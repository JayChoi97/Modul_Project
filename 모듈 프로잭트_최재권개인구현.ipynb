{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydirectinput\n",
      "  Downloading PyDirectInput-1.0.4-py3-none-any.whl (8.9 kB)\n",
      "Installing collected packages: pydirectinput\n",
      "Successfully installed pydirectinput-1.0.4\n"
     ]
    }
   ],
   "source": [
    "# !pip install pyautogui\n",
    "# !pip install numpy\n",
    "!pip install pydirectinput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모자 입히기 (미국모자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Mediapipe 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "def resize_image(image, target_width):\n",
    "    # 이미지의 너비를 목표 너비에 맞추고, 비율에 따라 높이를 조정합니다.\n",
    "    ratio = target_width / image.shape[1]\n",
    "    target_height = int(image.shape[0] * ratio)\n",
    "    target_dim = (target_width, target_height)\n",
    "    return cv2.resize(image, target_dim)\n",
    "\n",
    "# 모자 이미지 불러오기\n",
    "hat = cv2.imread('usa.png', cv2.IMREAD_UNCHANGED)\n",
    "if hat is None:\n",
    "    raise ValueError(\"모자 이미지를 불러올 수 없습니다. 파일 경로를 확인하세요.\")\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # 프레임 읽기\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # BGR을 RGB로 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 얼굴 랜드마크 검출\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for landmarks in results.multi_face_landmarks:\n",
    "            h, w, _ = frame.shape\n",
    "\n",
    "            # 이마의 중앙 상단 부분에 대한 랜드마크 포인트를 선택합니다.\n",
    "            forehead_point = landmarks.landmark[10]  # 중앙 이마 지점을 가져옵니다.\n",
    "            forehead_width = w // 4  # 이마 너비를 정의합니다.\n",
    "\n",
    "            if forehead_width > 0:\n",
    "                hat_resized = resize_image(hat, forehead_width)\n",
    "\n",
    "                # Calculate hat position\n",
    "                x_hat = int(forehead_point.x * w) - (hat_resized.shape[1] // 2)\n",
    "                y_hat = int(forehead_point.y * h) - (hat_resized.shape[0])\n",
    "\n",
    "                # Make sure the hat does not go off the edges of the frame\n",
    "                x_hat = max(0, min(x_hat, w - hat_resized.shape[1]))\n",
    "                y_hat = max(0, min(y_hat, h - hat_resized.shape[0]))\n",
    "\n",
    "                # Extract the region of the frame to be blended\n",
    "                hat_region = frame[y_hat:y_hat+hat_resized.shape[0], x_hat:x_hat+hat_resized.shape[1]]\n",
    "\n",
    "                # Create a mask for the alpha channel\n",
    "                mask = hat_resized[:, :, 3] / 255.0\n",
    "\n",
    "                # Ensure that mask and hat_region are of the same size\n",
    "                mask = mask[:hat_region.shape[0], :hat_region.shape[1]]\n",
    "\n",
    "                # Blend the hat with the frame\n",
    "                frame[y_hat:y_hat+hat_region.shape[0], x_hat:x_hat+hat_region.shape[1]] = (\n",
    "                    (1.0 - mask[..., None]) * hat_region + mask[..., None] * hat_resized[:, :, :3]\n",
    "                )\n",
    "\n",
    "    # 화면에 출력합니다.\n",
    "    cv2.imshow('Face Landmarks with Hat', frame)\n",
    "\n",
    "    # 종료 조건 설정 (q 키를 누르면 종료)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 리소스 해제 및 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모자 입히기(영국)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Mediapipe 초기화\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "def resize_image(image, target_width):\n",
    "    # 이미지의 너비를 목표 너비에 맞추고, 비율에 따라 높이를 조정합니다.\n",
    "    ratio = target_width / image.shape[1]\n",
    "    target_height = int(image.shape[0] * ratio)\n",
    "    target_dim = (target_width, target_height)\n",
    "    return cv2.resize(image, target_dim)\n",
    "\n",
    "# 모자 이미지 불러오기\n",
    "hat = cv2.imread('uk.png', cv2.IMREAD_UNCHANGED)\n",
    "if hat is None:\n",
    "    raise ValueError(\"모자 이미지를 불러올 수 없습니다. 파일 경로를 확인하세요.\")\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # 프레임 읽기\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # BGR을 RGB로 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 얼굴 랜드마크 검출\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for landmarks in results.multi_face_landmarks:\n",
    "            h, w, _ = frame.shape\n",
    "\n",
    "            # 이마의 중앙 상단 부분에 대한 랜드마크 포인트를 선택합니다.\n",
    "            forehead_point = landmarks.landmark[10]  # 중앙 이마 지점을 가져옵니다.\n",
    "            forehead_width = w // 4  # 이마 너비를 정의합니다.\n",
    "\n",
    "            if forehead_width > 0:\n",
    "                hat_resized = resize_image(hat, forehead_width)\n",
    "\n",
    "                # Calculate hat position\n",
    "                x_hat = int(forehead_point.x * w) - (hat_resized.shape[1] // 2)\n",
    "                y_hat = int(forehead_point.y * h) - (hat_resized.shape[0])\n",
    "\n",
    "                # Make sure the hat does not go off the edges of the frame\n",
    "                x_hat = max(0, min(x_hat, w - hat_resized.shape[1]))\n",
    "                y_hat = max(0, min(y_hat, h - hat_resized.shape[0]))\n",
    "\n",
    "                # Extract the region of the frame to be blended\n",
    "                hat_region = frame[y_hat:y_hat+hat_resized.shape[0], x_hat:x_hat+hat_resized.shape[1]]\n",
    "\n",
    "                # Create a mask for the alpha channel\n",
    "                mask = hat_resized[:, :, 3] / 255.0\n",
    "\n",
    "                # Ensure that mask and hat_region are of the same size\n",
    "                mask = mask[:hat_region.shape[0], :hat_region.shape[1]]\n",
    "\n",
    "                # Blend the hat with the frame\n",
    "                frame[y_hat:y_hat+hat_region.shape[0], x_hat:x_hat+hat_region.shape[1]] = (\n",
    "                    (1.0 - mask[..., None]) * hat_region + mask[..., None] * hat_resized[:, :, :3]\n",
    "                )\n",
    "\n",
    "    # 화면에 출력합니다.\n",
    "    cv2.imshow('Face Landmarks with Hat', frame)\n",
    "\n",
    "    # 종료 조건 설정 (q 키를 누르면 종료)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# 리소스 해제 및 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뒷배경 (일본)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 포즈 추적 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# 배경 이미지 불러오기\n",
    "shoulder_image_path = 'japan.png'  # 수정된 파일 경로\n",
    "shoulder_image = cv2.imread(shoulder_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# 이미지가 제대로 로드되었는지 확인\n",
    "if shoulder_image is None:\n",
    "    raise ValueError(f\"이미지를 불러올 수 없습니다. 파일 경로를 확인하세요: {shoulder_image_path}\")\n",
    "\n",
    "# 웹캠 초기화\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"웹캠에서 이미지를 불러오는 데 실패했습니다.\")\n",
    "        break\n",
    "    \n",
    "    # 이미지 처리\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = pose.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        # 왼쪽 어깨 랜드마크\n",
    "        left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "        \n",
    "        # 이미지를 왼쪽 어깨 위에 위치시킬 기준점 계산\n",
    "        reference_x = int(left_shoulder.x * image.shape[1])\n",
    "        reference_y = int(left_shoulder.y * image.shape[0])\n",
    "\n",
    "                # 배경 이미지의 크기 조정\n",
    "        scale_factor = 0.35 # 이미지 크기 비율을 더 크게 조정\n",
    "        new_width = int(image.shape[1] * scale_factor)\n",
    "        new_height = int(shoulder_image.shape[0] * new_width / shoulder_image.shape[1])\n",
    "        shoulder_image_resized = cv2.resize(shoulder_image, (new_width, new_height))\n",
    "        \n",
    "        # 배경 이미지를 왼쪽 어깨 위에 오버레이\n",
    "        try:\n",
    "            # 이미지 위치 조정 (x는 어깨의 왼쪽, y는 어깨 바로 위쪽에 위치시킴)\n",
    "            overlay_x = reference_x - new_width // 2\n",
    "            overlay_y = reference_y - new_height - 0  # 이미지를 더 위로 이동\n",
    "\n",
    "            # 이미지가 화면 밖으로 나가지 않도록 조정\n",
    "            overlay_x = max(0, min(overlay_x, image.shape[1] - new_width))\n",
    "            overlay_y = max(0, min(overlay_y, image.shape[0] - new_height))\n",
    "\n",
    "            overlay_end_x = overlay_x + new_width\n",
    "            overlay_end_y = overlay_y + new_height\n",
    "\n",
    "            # 알파 채널을 사용하여 이미지 오버레이\n",
    "\n",
    "            alpha_s = shoulder_image_resized[:, :, 3] / 255.0\n",
    "            alpha_l = 1.0 - alpha_s\n",
    "\n",
    "            for c in range(0, 3):\n",
    "                image[overlay_y:overlay_end_y, overlay_x:overlay_end_x, c] = (\n",
    "                    alpha_s * shoulder_image_resized[:, :, c] +\n",
    "                    alpha_l * image[overlay_y:overlay_end_y, overlay_x:overlay_end_x, c]\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"오버레이 오류: {e}\")\n",
    "\n",
    "    # 결과를 화면에 보여줌\n",
    "    cv2.imshow('Webcam Feed', image)\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뒷배경(스페인-마드리드) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 포즈 추적 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# 배경 이미지 불러오기\n",
    "shoulder_image_path = 'madrid.png'  # 수정된 파일 경로\n",
    "shoulder_image = cv2.imread(shoulder_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# 이미지가 제대로 로드되었는지 확인\n",
    "if shoulder_image is None:\n",
    "    raise ValueError(f\"이미지를 불러올 수 없습니다. 파일 경로를 확인하세요: {shoulder_image_path}\")\n",
    "\n",
    "# 웹캠 초기화\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"웹캠에서 이미지를 불러오는 데 실패했습니다.\")\n",
    "        break\n",
    "    \n",
    "    # 이미지 처리\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = pose.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        # 왼쪽 어깨 랜드마크\n",
    "        left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "        \n",
    "        # 이미지를 왼쪽 어깨 위에 위치시킬 기준점 계산\n",
    "        reference_x = int(left_shoulder.x * image.shape[1])\n",
    "        reference_y = int(left_shoulder.y * image.shape[0])\n",
    "\n",
    "                # 배경 이미지의 크기 조정\n",
    "        scale_factor = 0.2 # 이미지 크기 비율을 더 크게 조정\n",
    "        new_width = int(image.shape[1] * scale_factor)\n",
    "        new_height = int(shoulder_image.shape[0] * new_width / shoulder_image.shape[1])\n",
    "        shoulder_image_resized = cv2.resize(shoulder_image, (new_width, new_height))\n",
    "        \n",
    "        # 배경 이미지를 왼쪽 어깨 위에 오버레이\n",
    "        try:\n",
    "            # 이미지 위치 조정 (x는 어깨의 왼쪽, y는 어깨 바로 위쪽에 위치시킴)\n",
    "            overlay_x = reference_x - new_width // 2\n",
    "            overlay_y = reference_y - new_height - 60  # 이미지를 더 위로 이동\n",
    "\n",
    "            # 이미지가 화면 밖으로 나가지 않도록 조정\n",
    "            overlay_x = max(0, min(overlay_x, image.shape[1] - new_width))\n",
    "            overlay_y = max(0, min(overlay_y, image.shape[0] - new_height))\n",
    "\n",
    "            overlay_end_x = overlay_x + new_width\n",
    "            overlay_end_y = overlay_y + new_height\n",
    "\n",
    "            # 알파 채널을 사용하여 이미지 오버레이\n",
    "\n",
    "            alpha_s = shoulder_image_resized[:, :, 3] / 255.0\n",
    "            alpha_l = 1.0 - alpha_s\n",
    "\n",
    "            for c in range(0, 3):\n",
    "                image[overlay_y:overlay_end_y, overlay_x:overlay_end_x, c] = (\n",
    "                    alpha_s * shoulder_image_resized[:, :, c] +\n",
    "                    alpha_l * image[overlay_y:overlay_end_y, overlay_x:overlay_end_x, c]\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"오버레이 오류: {e}\")\n",
    "\n",
    "    # 결과를 화면에 보여줌\n",
    "    cv2.imshow('Webcam Feed', image)\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어깨위 나타내기(프랑스-파리)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 포즈 추적 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# 배경 이미지 불러오기\n",
    "shoulder_image_path = 'paris.png'  # 수정된 파일 경로\n",
    "shoulder_image = cv2.imread(shoulder_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# 이미지가 제대로 로드되었는지 확인\n",
    "if shoulder_image is None:\n",
    "    raise ValueError(f\"이미지를 불러올 수 없습니다. 파일 경로를 확인하세요: {shoulder_image_path}\")\n",
    "\n",
    "# 웹캠 초기화\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"웹캠에서 이미지를 불러오는 데 실패했습니다.\")\n",
    "        break\n",
    "    \n",
    "    # 이미지 처리\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = pose.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        # 왼쪽 어깨 랜드마크\n",
    "        left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]\n",
    "        \n",
    "        # 이미지를 왼쪽 어깨 위에 위치시킬 기준점 계산\n",
    "        reference_x = int(left_shoulder.x * image.shape[1])\n",
    "        reference_y = int(left_shoulder.y * image.shape[0])\n",
    "\n",
    "                # 배경 이미지의 크기 조정\n",
    "        scale_factor = 0.3 # 이미지 크기 비율을 더 크게 조정\n",
    "        new_width = int(image.shape[1] * scale_factor)\n",
    "        new_height = int(shoulder_image.shape[0] * new_width / shoulder_image.shape[1])\n",
    "        shoulder_image_resized = cv2.resize(shoulder_image, (new_width, new_height))\n",
    "        \n",
    "        # 배경 이미지를 왼쪽 어깨 위에 오버레이\n",
    "        try:\n",
    "            # 이미지 위치 조정 (x는 어깨의 왼쪽, y는 어깨 바로 위쪽에 위치시킴)\n",
    "            overlay_x = reference_x - new_width // 2\n",
    "            overlay_y = reference_y - new_height - 60  # 이미지를 더 위로 이동\n",
    "\n",
    "            # 이미지가 화면 밖으로 나가지 않도록 조정\n",
    "            overlay_x = max(0, min(overlay_x, image.shape[1] - new_width))\n",
    "            overlay_y = max(0, min(overlay_y, image.shape[0] - new_height))\n",
    "\n",
    "            overlay_end_x = overlay_x + new_width\n",
    "            overlay_end_y = overlay_y + new_height\n",
    "\n",
    "            # 알파 채널을 사용하여 이미지 오버레이\n",
    "\n",
    "            alpha_s = shoulder_image_resized[:, :, 3] / 255.0\n",
    "            alpha_l = 1.0 - alpha_s\n",
    "\n",
    "            for c in range(0, 3):\n",
    "                image[overlay_y:overlay_end_y, overlay_x:overlay_end_x, c] = (\n",
    "                    alpha_s * shoulder_image_resized[:, :, c] +\n",
    "                    alpha_l * image[overlay_y:overlay_end_y, overlay_x:overlay_end_x, c]\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"오버레이 오류: {e}\")\n",
    "\n",
    "    # 결과를 화면에 보여줌\n",
    "    cv2.imshow('Webcam Feed', image)\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L자 인식시 사진 촬영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진이 촬영되었습니다!\n",
      "사진이 촬영되었습니다!\n",
      "사진이 촬영되었습니다!\n",
      "사진이 촬영되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Mediapipe 초기화\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# 카메라 열기나도 너무 재밌엇\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 손 모델 초기화\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    last_capture_time = time.time()  # 마지막 촬영 시간 초기화\n",
    "    capture_interval = 2  # 촬영 간격 (초)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR을 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 손 감지 수행\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        # 손 키포인트를 그리기 위한 코드\n",
    "        if results.multi_hand_landmarks:\n",
    "            for landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # 검지와 엄지 각도 계산\n",
    "                index_finger = landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                thumb = landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                distance = cv2.norm(\n",
    "                    (index_finger.x, index_finger.y),\n",
    "                    (thumb.x, thumb.y)\n",
    "                )\n",
    "\n",
    "                # 일정 각도 이상이면 2초 뒤에 사진 촬영\n",
    "                if distance > 0.1:  # 이 값은 실험을 통해 조절할 수 있습니다.\n",
    "                    current_time = time.time()\n",
    "                    if current_time - last_capture_time >= capture_interval:\n",
    "                        cv2.imwrite('captured_image.jpg', frame)\n",
    "                        print(\"사진이 촬영되었습니다!\")\n",
    "                        last_capture_time = current_time\n",
    "\n",
    "        cv2.imshow('Hand Pose Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 종료 시 리소스 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사진과 웹캠 뜨게하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사진이 촬영되었습니다!\n",
      "사진이 촬영되었습니다!\n",
      "사진이 촬영되었습니다!\n",
      "사진이 촬영되었습니다!\n",
      "사진이 촬영되었습니다!\n",
      "사진이 촬영되었습니다!\n",
      "사진이 촬영되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Mediapipe 초기화\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 손 모델 초기화\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    last_capture_time = time.time()  # 마지막 촬영 시간 초기화\n",
    "    capture_interval = 2  # 촬영 간격 (초)\n",
    "    \n",
    "    # 사용자가 원하는 이미지 경로 설정\n",
    "    desired_image_path = 'test.jfif'\n",
    "    # 이미지 불러오기\n",
    "    desired_image = cv2.imread(desired_image_path)\n",
    "    \n",
    "    if desired_image is None:\n",
    "        print(f\"이미지를 불러오지 못했습니다. 경로를 확인해주세요: {desired_image_path}\")\n",
    "        exit()\n",
    "\n",
    "    # 이미지 창 초기화\n",
    "    cv2.namedWindow('내가 원하는 이미지', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('내가 원하는 이미지', desired_image)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR을 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 손 감지 수행\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        # 손 키포인트를 그리기 위한 코드\n",
    "        if results.multi_hand_landmarks:\n",
    "            for landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # 검지와 엄지 각도 계산\n",
    "                index_finger = landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                thumb = landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                distance = cv2.norm(\n",
    "                    (index_finger.x, index_finger.y),\n",
    "                    (thumb.x, thumb.y)\n",
    "                )\n",
    "\n",
    "                # 일정 각도 이상이면 2초 뒤에 사진 촬영\n",
    "                if distance > 0.1:  # 이 값은 실험을 통해 조절할 수 있습니다.\n",
    "                    current_time = time.time()\n",
    "                    if current_time - last_capture_time >= capture_interval:\n",
    "                        cv2.imwrite('captured_image.jpg', frame)\n",
    "                        print(\"사진이 촬영되었습니다!\")\n",
    "                        last_capture_time = current_time\n",
    "\n",
    "        # 웹캠 화면 표시\n",
    "        cv2.imshow('손 포즈 감지', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 종료 시 리소스 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사진, 웹캠 같이 촬영"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내가 원하는 이미지와 함께 촬영되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Mediapipe 초기화\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 손 모델 초기화\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    last_capture_time = time.time()  # 마지막 촬영 시간 초기화\n",
    "    capture_interval = 2  # 촬영 간격 (초)\n",
    "    \n",
    "    # 사용자가 원하는 이미지 경로 설정\n",
    "    desired_image_path = 'test.jfif'\n",
    "    # 이미지 불러오기\n",
    "    desired_image = cv2.imread(desired_image_path)\n",
    "    \n",
    "    if desired_image is None:\n",
    "        print(f\"이미지를 불러오지 못했습니다. 경로를 확인해주세요: {desired_image_path}\")\n",
    "        exit()\n",
    "\n",
    "    # 이미지 창 초기화\n",
    "    cv2.namedWindow('내가 원하는 이미지', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('내가 원하는 이미지', desired_image)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR을 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 손 감지 수행\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        # 손 키포인트를 그리기 위한 코드\n",
    "        if results.multi_hand_landmarks:\n",
    "            for landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # 검지와 엄지 각도 계산\n",
    "                index_finger = landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                thumb = landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                distance = cv2.norm(\n",
    "                    (index_finger.x, index_finger.y),\n",
    "                    (thumb.x, thumb.y)\n",
    "                )\n",
    "\n",
    "                # 일정 각도 이상이면 2초 뒤에 사진 촬영\n",
    "                if distance > 0.1:  # 이 값은 실험을 통해 조절할 수 있습니다.\n",
    "                    current_time = time.time()\n",
    "                    if current_time - last_capture_time >= capture_interval:\n",
    "                        # 웹캠 화면 크기를 사용자가 지정한 이미지 크기에 맞추기\n",
    "                        resized_frame = cv2.resize(frame, (desired_image.shape[1], desired_image.shape[0]))\n",
    "                        \n",
    "                        # 현재 웹캠 화면 저장\n",
    "                        cv2.imwrite('captured_webcam_image.jpg', resized_frame)\n",
    "                        print(\"웹캠 화면이 촬영되었습니다!\")\n",
    "\n",
    "                        # 내가 원하는 이미지와 함께 저장\n",
    "                        combined_image = cv2.hconcat([resized_frame, desired_image])\n",
    "                        cv2.imwrite('combined_image.jpg', combined_image)\n",
    "                        print(\"내가 원하는 이미지와 함께 촬영되었습니다!\")\n",
    "\n",
    "                        last_capture_time = current_time\n",
    "\n",
    "        # 웹캠 화면 표시\n",
    "        cv2.imshow('손 포즈 감지', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 종료 시 리소스 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "포즈시 설정한 사진만 찍히게 하기(웹캠은 X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내가 원하는 이미지와 함께 촬영되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Mediapipe 초기화\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 손 모델 초기화\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    last_capture_time = time.time()  # 마지막 촬영 시간 초기화\n",
    "    capture_interval = 2  # 촬영 간격 (초)\n",
    "    \n",
    "    # 사용자가 원하는 이미지 경로 설정\n",
    "    desired_image_path = 'test.jfif'\n",
    "    # 이미지 불러오기\n",
    "    desired_image = cv2.imread(desired_image_path)\n",
    "    \n",
    "    if desired_image is None:\n",
    "        print(f\"이미지를 불러오지 못했습니다. 경로를 확인해주세요: {desired_image_path}\")\n",
    "        exit()\n",
    "\n",
    "    # 이미지 창 초기화\n",
    "    cv2.namedWindow('내가 원하는 이미지', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('내가 원하는 이미지', desired_image)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR을 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 손 감지 수행\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        # 손 키포인트를 그리기 위한 코드\n",
    "        if results.multi_hand_landmarks:\n",
    "            for landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # 검지와 엄지 각도 계산\n",
    "                index_finger = landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                thumb = landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                distance = cv2.norm(\n",
    "                    (index_finger.x, index_finger.y),\n",
    "                    (thumb.x, thumb.y)\n",
    "                )\n",
    "\n",
    "                # 일정 각도 이상이면 2초 뒤에 내가 원하는 이미지만 촬영\n",
    "                if distance > 0.1: \n",
    "                    current_time = time.time()\n",
    "                    if current_time - last_capture_time >= capture_interval:\n",
    "                        \n",
    "                        # 내가 원하는 이미지와 함께 촬영\n",
    "                        cv2.imwrite('captured_desired_image.jpg', desired_image)\n",
    "                        print(\"내가 원하는 이미지와 함께 촬영되었습니다!\")\n",
    "\n",
    "                        last_capture_time = current_time\n",
    "\n",
    "        # 웹캠 화면 표시\n",
    "        cv2.imshow('손 포즈 감지', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 종료 시 리소스 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "촬영 효과 추가 (ver.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내가 원하는 이미지와 함께 촬영되었습니다!\n",
      "내가 원하는 이미지와 함께 촬영되었습니다!\n",
      "내가 원하는 이미지와 함께 촬영되었습니다!\n",
      "내가 원하는 이미지와 함께 촬영되었습니다!\n",
      "내가 원하는 이미지와 함께 촬영되었습니다!\n",
      "내가 원하는 이미지와 함께 촬영되었습니다!\n",
      "내가 원하는 이미지와 함께 촬영되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Mediapipe 초기화\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 손 모델 초기화\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    last_capture_time = time.time()  # 마지막 촬영 시간 초기화\n",
    "    capture_interval = 2  # 촬영 간격 (초)\n",
    "    \n",
    "    # 사용자가 원하는 이미지 경로 설정\n",
    "    desired_image_path = 'test.jfif'\n",
    "    # 이미지 불러오기\n",
    "    desired_image = cv2.imread(desired_image_path)\n",
    "    \n",
    "    if desired_image is None:\n",
    "        print(f\"이미지를 불러오지 못했습니다. 경로를 확인해주세요: {desired_image_path}\")\n",
    "        exit()\n",
    "\n",
    "    # 이미지 창 초기화\n",
    "    cv2.namedWindow('내가 원하는 이미지', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('내가 원하는 이미지', desired_image)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR을 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 손 감지 수행\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        # 손 키포인트를 그리기 위한 코드\n",
    "        if results.multi_hand_landmarks:\n",
    "            for landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # 검지와 엄지 각도 계산\n",
    "                index_finger = landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                thumb = landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                distance = cv2.norm(\n",
    "                    (index_finger.x, index_finger.y),\n",
    "                    (thumb.x, thumb.y)\n",
    "                )\n",
    "\n",
    "                # 일정 각도 이상이면 2초 뒤에 내가 원하는 이미지만 촬영\n",
    "                if distance > 0.1: \n",
    "                    current_time = time.time()\n",
    "                    if current_time - last_capture_time >= capture_interval:\n",
    "                        \n",
    "                        # 화면 어둡게 만들기 (가중치 조절 가능)\n",
    "                        dark_frame = np.zeros_like(frame)\n",
    "                        alpha = 0.1\n",
    "                        cv2.addWeighted(frame, alpha, dark_frame, 1 - alpha, 0, frame)\n",
    "                        \n",
    "                        # 내가 원하는 이미지와 함께 촬영\n",
    "                        cv2.imwrite('captured_desired_image.jpg', desired_image)\n",
    "                        print(\"내가 원하는 이미지와 함께 촬영되었습니다!\")\n",
    "\n",
    "                        last_capture_time = current_time\n",
    "\n",
    "        # 웹캠 화면 표시\n",
    "        cv2.imshow('손 포즈 감지', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 종료 시 리소스 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "촬영 효과 추가(ver.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내가 원하는 이미지와 함께 촬영되었습니다!\n",
      "내가 원하는 이미지와 함께 촬영되었습니다!\n",
      "내가 원하는 이미지와 함께 촬영되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Mediapipe 초기화\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 손 모델 초기화\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    last_capture_time = time.time()  # 마지막 촬영 시간 초기화\n",
    "    capture_interval = 2  # 촬영 간격 (초)\n",
    "    fade_duration = 1.0  # 효과가 서서히 나타나는 시간 (초)\n",
    "    \n",
    "    # 사용자가 원하는 이미지 경로 설정\n",
    "    desired_image_path = 'test.jfif'\n",
    "    # 이미지 불러오기\n",
    "    desired_image = cv2.imread(desired_image_path)\n",
    "    \n",
    "    if desired_image is None:\n",
    "        print(f\"이미지를 불러오지 못했습니다. 경로를 확인해주세요: {desired_image_path}\")\n",
    "        exit()\n",
    "\n",
    "    # 이미지 창 초기화\n",
    "    cv2.namedWindow('내가 원하는 이미지', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('내가 원하는 이미지', desired_image)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR을 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 손 감지 수행\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        # 손 키포인트를 그리기 위한 코드\n",
    "        if results.multi_hand_landmarks:\n",
    "            for landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # 검지와 엄지 각도 계산\n",
    "                index_finger = landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                thumb = landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                distance = cv2.norm(\n",
    "                    (index_finger.x, index_finger.y),\n",
    "                    (thumb.x, thumb.y)\n",
    "                )\n",
    "\n",
    "                # 일정 각도 이상이면 2초 뒤에 내가 원하는 이미지만 촬영\n",
    "                if distance > 0.1:  # 이 값은 실험을 통해 조절할 수 있습니다.\n",
    "                    current_time = time.time()\n",
    "                    if current_time - last_capture_time >= capture_interval:\n",
    "                        \n",
    "                        # 효과 서서히 나타나게 만들기\n",
    "                        alpha_dark = 0.0\n",
    "                        while alpha_dark < 1.0:\n",
    "                            dark_frame = np.zeros_like(frame)\n",
    "                            cv2.addWeighted(frame, 1 - alpha_dark, dark_frame, alpha_dark, 0, frame)\n",
    "                            cv2.imshow('손 포즈 감지', frame)\n",
    "                            alpha_dark += 0.01  # 효과 나타나는 속도 조절\n",
    "                            if cv2.waitKey(int(fade_duration * 1000 / 100)) & 0xFF == 27:\n",
    "                                break\n",
    "\n",
    "                        # 내가 원하는 이미지와 함께 촬영\n",
    "                        cv2.imwrite('captured_desired_image.jpg', desired_image)\n",
    "                        print(\"내가 원하는 이미지와 함께 촬영되었습니다!\")\n",
    "\n",
    "                        # 효과 서서히 사라지게 만들기\n",
    "                        alpha_light = 1.0\n",
    "                        while alpha_light > 0.0:\n",
    "                            light_frame = np.zeros_like(frame)\n",
    "                            cv2.addWeighted(frame, 1 - alpha_light, light_frame, alpha_light, 0, frame)\n",
    "                            cv2.imshow('손 포즈 감지', frame)\n",
    "                            alpha_light -= 0.01  # 효과 사라지는 속도 조절\n",
    "                            if cv2.waitKey(int(fade_duration * 100 / 100)) & 0xFF == 27:\n",
    "                                break\n",
    "\n",
    "                        last_capture_time = current_time\n",
    "\n",
    "        # 웹캠 화면 표시\n",
    "        cv2.imshow('손 포즈 감지', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 종료 시 리소스 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "내가 원하는 이미지와 함께 촬영되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Mediapipe 초기화\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 손 모델 초기화\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    last_capture_time = time.time()  # 마지막 촬영 시간 초기화\n",
    "    capture_interval = 2  # 촬영 간격 (초)\n",
    "    \n",
    "    # 사용자가 원하는 이미지 경로 설정\n",
    "    desired_image_path = 'test.jfif'\n",
    "    # 이미지 불러오기\n",
    "    desired_image = cv2.imread(desired_image_path)\n",
    "    \n",
    "    if desired_image is None:\n",
    "        print(f\"이미지를 불러오지 못했습니다. 경로를 확인해주세요: {desired_image_path}\")\n",
    "        exit()\n",
    "\n",
    "    # 이미지 창 초기화\n",
    "    cv2.namedWindow('내가 원하는 이미지', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('내가 원하는 이미지', desired_image)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR을 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 손 감지 수행\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        # 손 키포인트를 그리기 위한 코드\n",
    "        if results.multi_hand_landmarks:\n",
    "            for landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # 검지와 엄지 각도 계산\n",
    "                index_finger = landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                thumb = landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "                distance = cv2.norm(\n",
    "                    (index_finger.x, index_finger.y),\n",
    "                    (thumb.x, thumb.y)\n",
    "                )\n",
    "\n",
    "                # 일정 각도 이상이면 2초 뒤에 내가 원하는 이미지만 촬영\n",
    "                if distance > 0.1:  \n",
    "                    current_time = time.time()\n",
    "                    if current_time - last_capture_time >= capture_interval:\n",
    "                        \n",
    "                        # 화면 어둡게 만들기 (가중치 조절 가능)\n",
    "                        dark_frame = np.zeros_like(frame)\n",
    "                        alpha = 0.1\n",
    "                        cv2.addWeighted(frame, alpha, dark_frame, 1 - alpha, 0, frame)\n",
    "                        \n",
    "                        # 내가 원하는 이미지와 함께 촬영\n",
    "                        cv2.imwrite('captured_desired_image.jpg', desired_image)\n",
    "                        print(\"내가 원하는 이미지와 함께 촬영되었습니다!\")\n",
    "\n",
    "                        last_capture_time = current_time\n",
    "\n",
    "                        # 이미지 촬영 후 검은 화면이 뜨고 2초 후 창이 자동으로 닫히게 설정\n",
    "                        cv2.imshow('손 포즈 감지', np.zeros_like(frame))\n",
    "                        cv2.waitKey(10)  \n",
    "                        break\n",
    "\n",
    "        # 웹캠 화면 표시\n",
    "        cv2.imshow('손 포즈 감지', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 종료 시 리소스 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'norm'\n> Overload resolution failed:\n>  - src1 is not a numerical tuple\n>  - Expected Ptr<cv::UMat> for argument 'src1'\n>  - src1 is not a numerical tuple\n>  - Expected Ptr<cv::UMat> for argument 'src1'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m thumb \u001b[38;5;241m=\u001b[39m landmarks\u001b[38;5;241m.\u001b[39mlandmark[mp_hands\u001b[38;5;241m.\u001b[39mHandLandmark\u001b[38;5;241m.\u001b[39mTHUMB_TIP]\n\u001b[0;32m     51\u001b[0m indexMCP \u001b[38;5;241m=\u001b[39m landmarks\u001b[38;5;241m.\u001b[39mlandmark[mp_hands\u001b[38;5;241m.\u001b[39mHandLandmark\u001b[38;5;241m.\u001b[39mINDEX_FINGER_MCP]\n\u001b[1;32m---> 52\u001b[0m distance \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_finger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_finger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_finger\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex_finger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mthumb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthumb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthumb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m distance1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mnorm(\n\u001b[0;32m     57\u001b[0m     (index_finger\u001b[38;5;241m.\u001b[39mx, index_finger\u001b[38;5;241m.\u001b[39my, index_finger\u001b[38;5;241m.\u001b[39mz),\n\u001b[0;32m     58\u001b[0m     (indexMCP\u001b[38;5;241m.\u001b[39mx, indexMCP\u001b[38;5;241m.\u001b[39my, indexMCP\u001b[38;5;241m.\u001b[39mz)\n\u001b[0;32m     59\u001b[0m )\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'norm'\n> Overload resolution failed:\n>  - src1 is not a numerical tuple\n>  - Expected Ptr<cv::UMat> for argument 'src1'\n>  - src1 is not a numerical tuple\n>  - Expected Ptr<cv::UMat> for argument 'src1'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Mediapipe 초기화\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 손 모델 초기화\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    last_capture_time = time.time()  # 마지막 촬영 시간 초기화\n",
    "    capture_interval = 2  # 촬영 간격 (초)\n",
    "    \n",
    "    # 사용자가 원하는 이미지 경로 설정\n",
    "    desired_image_path = 'test.jfif'\n",
    "    # 이미지 불러오기\n",
    "    desired_image = cv2.imread(desired_image_path)\n",
    "    \n",
    "    if desired_image is None:\n",
    "        print(f\"이미지를 불러오지 못했습니다. 경로를 확인해주세요: {desired_image_path}\")\n",
    "        exit()\n",
    "\n",
    "    # 이미지 창 초기화\n",
    "    cv2.namedWindow('내가 원하는 이미지', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('내가 원하는 이미지', desired_image)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGR을 RGB로 변환\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 손 감지 수행\n",
    "        results = hands.process(rgb_frame)\n",
    "\n",
    "        # 손 키포인트를 그리기 위한 코드\n",
    "        if results.multi_hand_landmarks:\n",
    "            for landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                # 검지와 엄지 각도 계산\n",
    "                index_finger = landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                thumb = landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "\n",
    "                indexMCP = landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "                distance = cv2.norm(\n",
    "                    (index_finger.x, index_finger.y, index_finger,index_finger.z),\n",
    "                    (thumb.x, thumb.y, thumb.z)\n",
    "                )\n",
    "                distance1 = cv2.norm(\n",
    "                    (index_finger.x, index_finger.y, index_finger.z),\n",
    "                    (indexMCP.x, indexMCP.y, indexMCP.z)\n",
    "                )\n",
    "                if results.pose_landmarks:\n",
    "                    distance2 = finger_distance1\n",
    "                else:\n",
    "                    distance2 = 1\n",
    "                print(distance2)\n",
    "                if distance/distance1 > 1.4 and distance2 < 0.3:\n",
    "                    current_time = time.time()\n",
    "\n",
    "                if current_time - last_capture_time >= capture_interval:\n",
    "                    saredPicture.value = 1\n",
    "                # 일정 각도 이상이면 2초 뒤에 내가 원하는 이미지만 촬영\n",
    "                if distance > 0.1:  \n",
    "                    current_time = time.time()\n",
    "                    if current_time - last_capture_time >= capture_interval:\n",
    "                        \n",
    "                        # 화면 어둡게 만들기 (가중치 조절 가능)\n",
    "                        dark_frame = np.zeros_like(frame)\n",
    "                        alpha = 0.1\n",
    "                        cv2.addWeighted(frame, alpha, dark_frame, 1 - alpha, 0, frame)\n",
    "                        \n",
    "                        # 내가 원하는 이미지와 함께 촬영\n",
    "                        cv2.imwrite('captured_desired_image.jpg', desired_image)\n",
    "                        print(\"내가 원하는 이미지와 함께 촬영되었습니다!\")\n",
    "\n",
    "                        last_capture_time = current_time\n",
    "\n",
    "                        # 이미지 촬영 후 검은 화면이 뜨고 2초 후 창이 자동으로 닫히게 설정\n",
    "                        cv2.imshow('손 포즈 감지', np.zeros_like(frame))\n",
    "                        cv2.waitKey(10)  \n",
    "                        break\n",
    "\n",
    "        # 웹캠 화면 표시\n",
    "        cv2.imshow('손 포즈 감지', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# 종료 시 리소스 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
